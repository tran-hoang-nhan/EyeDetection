{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Eye State Classifier Training\n",
    "Training pipeline v·ªõi SVM v√† Random Forest ƒë·ªÉ ph√¢n lo·∫°i m·∫Øt m·ªü/nh·∫Øm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from utils.feature_extractor import extract_eye_features, preprocess_eye_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Advanced Eye State Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Advanced Eye State Classifier initialized\n"
     ]
    }
   ],
   "source": [
    "class AdvancedEyeStateClassifier:\n",
    "    def __init__(self):\n",
    "        # === PIPELINES ===\n",
    "        self.pipelines = {\n",
    "            'svm': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('classifier', SVC(probability=True, random_state=42))\n",
    "            ]),\n",
    "            'random_forest': Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "            ])\n",
    "        }\n",
    "\n",
    "        self.best_pipeline = None\n",
    "        self.best_accuracy = 0\n",
    "        self.best_pipeline_name = \"\"\n",
    "\n",
    "# Initialize classifier\n",
    "classifier = AdvancedEyeStateClassifier()\n",
    "print(\"üéØ Advanced Eye State Classifier initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset with Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading dataset with preprocessing + feature extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 42952 open eye images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42952/42952 [00:35<00:00, 1225.64it/s]\n",
      "Processing 41946 closed eye images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41946/41946 [00:35<00:00, 1196.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded: 84898 samples\n",
      "   Features per sample: 25\n",
      "   Open eyes: 42952\n",
      "   Closed eyes: 41946\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(data_path='data/eyes'):\n",
    "    \"\"\"Load, preprocess and extract features from dataset\"\"\"\n",
    "    X, y = [], []\n",
    "\n",
    "    print(\"üìÇ Loading dataset with preprocessing + feature extraction...\")\n",
    "\n",
    "    # Load open eyes (label = 1)\n",
    "    open_path = os.path.join(data_path, 'open')\n",
    "    if os.path.exists(open_path):\n",
    "        open_files = [f for f in os.listdir(open_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "\n",
    "        for img_name in tqdm(open_files, desc=f\"Processing {len(open_files)} open eye images\"):\n",
    "            img_path = os.path.join(open_path, img_name)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None and img.size > 0:\n",
    "                # PREPROCESSING\n",
    "                img = preprocess_eye_image(img)\n",
    "\n",
    "                # FEATURE EXTRACTION\n",
    "                features = extract_eye_features(img)\n",
    "                if not np.any(np.isnan(features)):\n",
    "                    X.append(features)\n",
    "                    y.append(1)\n",
    "\n",
    "    # Load closed eyes (label = 0)\n",
    "    closed_path = os.path.join(data_path, 'closed')\n",
    "    if os.path.exists(closed_path):\n",
    "        closed_files = [f for f in os.listdir(closed_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "\n",
    "        for img_name in tqdm(closed_files, desc=f\"Processing {len(closed_files)} closed eye images\"):\n",
    "            img_path = os.path.join(closed_path, img_name)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None and img.size > 0:\n",
    "                # PREPROCESSING\n",
    "                img = preprocess_eye_image(img)\n",
    "\n",
    "                # FEATURE EXTRACTION\n",
    "                features = extract_eye_features(img)\n",
    "                if not np.any(np.isnan(features)):\n",
    "                    X.append(features)\n",
    "                    y.append(0)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_dataset()\n",
    "\n",
    "if len(X) == 0:\n",
    "    print(\"‚ùå No valid data found! Please check data/eyes/ folders\")\n",
    "else:\n",
    "    print(f\"‚úÖ Dataset loaded: {len(X)} samples\")\n",
    "    print(f\"   Features per sample: {X.shape[1] if len(X.shape) > 1 else 'Unknown'}\")\n",
    "    print(f\"   Open eyes: {np.sum(y == 1)}\")\n",
    "    print(f\"   Closed eyes: {np.sum(y == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Models with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Pipeline Training...\n",
      "üîç Quick model screening...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Screening models:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [20:56<20:56, 1256.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   svm: 0.9352 (¬±0.0004)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Screening models: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [21:10<00:00, 635.14s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   random_forest: 0.9529 (¬±0.0005)\n",
      "\n",
      "üéØ Optimizing top models: random_forest, svm\n",
      "\n",
      "ü§ñ Optimizing random_forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Best params: {'classifier__max_depth': None, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200}\n",
      "   Accuracy: 0.9584\n",
      "   CV Score: 0.9554\n",
      "\n",
      "ü§ñ Optimizing svm...\n",
      "   Best params: {'classifier__C': 10, 'classifier__gamma': 'scale'}\n",
      "   Accuracy: 0.9524\n",
      "   CV Score: 0.9487\n"
     ]
    }
   ],
   "source": [
    "def train_models_with_cv(X, y):\n",
    "    \"\"\"Train pipelines with optimized strategy for best accuracy\"\"\"\n",
    "    print(\"\\nüöÄ Pipeline Training...\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Strategy 1: Quick screening of all models\n",
    "    print(\"üîç Quick model screening...\")\n",
    "    for name, pipeline in tqdm(classifier.pipelines.items(), desc=\"Screening models\"):\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='accuracy')\n",
    "        results[name] = {\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std()\n",
    "        }\n",
    "        print(f\"   {name}: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})\")\n",
    "\n",
    "    # Strategy 2: Focus on top 2 performers with hyperparameter tuning\n",
    "    sorted_models = sorted(results.items(), key=lambda x: x[1]['cv_mean'], reverse=True)\n",
    "    top_models = [model[0] for model in sorted_models[:2]]\n",
    "\n",
    "    print(f\"\\nüéØ Optimizing top models: {', '.join(top_models)}\")\n",
    "\n",
    "    final_results = {}\n",
    "\n",
    "    for name in top_models:\n",
    "        print(f\"\\nü§ñ Optimizing {name}...\")\n",
    "\n",
    "        # Hyperparameter tuning for top models\n",
    "        if name == 'random_forest':\n",
    "            param_grid = {\n",
    "                'classifier__n_estimators': [100, 200],\n",
    "                'classifier__max_depth': [10, 20, None],\n",
    "                'classifier__min_samples_split': [2, 5]\n",
    "            }\n",
    "        elif name == 'svm':\n",
    "            param_grid = {\n",
    "                'classifier__C': [1, 10],\n",
    "                'classifier__gamma': ['scale', 'auto']\n",
    "            }\n",
    "\n",
    "        # GridSearchCV with limited scope for speed\n",
    "        grid_search = GridSearchCV(\n",
    "            classifier.pipelines[name],\n",
    "            param_grid,\n",
    "            cv=5,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "        # Evaluate on test set\n",
    "        y_pred = best_pipeline.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        final_results[name] = {\n",
    "            'pipeline': best_pipeline,\n",
    "            'accuracy': accuracy,\n",
    "            'cv_mean': grid_search.best_score_,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'y_test': y_test,\n",
    "            'y_pred': y_pred\n",
    "        }\n",
    "\n",
    "        print(f\"   Best params: {grid_search.best_params_}\")\n",
    "        print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"   CV Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "        if accuracy > classifier.best_accuracy:\n",
    "            classifier.best_accuracy = accuracy\n",
    "            classifier.best_pipeline = best_pipeline\n",
    "            classifier.best_pipeline_name = name\n",
    "\n",
    "    return final_results\n",
    "\n",
    "# Train models\n",
    "if len(X) > 0:\n",
    "    results = train_models_with_cv(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results):\n",
    "    \"\"\"Visualize training results\"\"\"\n",
    "    try:\n",
    "        models = list(results.keys())\n",
    "        accuracies = [results[model]['accuracy'] for model in models]\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        bars = plt.bar(models, accuracies, color=['skyblue', 'lightgreen', 'salmon', 'gold'])\n",
    "        plt.title('Pipeline Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylim(0.9, 1.0)\n",
    "\n",
    "        for bar, acc in zip(bars, accuracies):\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.002,\n",
    "                     f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        best_result = results[classifier.best_pipeline_name]\n",
    "        cm = confusion_matrix(best_result['y_test'], best_result['y_pred'])\n",
    "\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(f'Best: {classifier.best_pipeline_name}')\n",
    "        plt.colorbar()\n",
    "\n",
    "        tick_marks = np.arange(2)\n",
    "        plt.xticks(tick_marks, ['Closed', 'Open'])\n",
    "        plt.yticks(tick_marks, ['Closed', 'Open'])\n",
    "\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                plt.text(j, i, cm[i, j], ha='center', va='center')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('models/training_results.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Visualization error: {e}\")\n",
    "\n",
    "# Plot results\n",
    "if len(X) > 0 and 'results' in locals():\n",
    "    plot_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Display Best Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "if len(X) > 0 and 'results' in locals():\n",
    "    print(f\"\\nüèÜ Best Model: {classifier.best_pipeline_name}\")\n",
    "    print(f\"   Accuracy: {classifier.best_accuracy:.4f}\")\n",
    "\n",
    "    # Generate detailed report for best model\n",
    "    best_result = results[classifier.best_pipeline_name]\n",
    "    print(f\"\\nüìä Detailed Report for {classifier.best_pipeline_name}:\")\n",
    "    print(classification_report(\n",
    "        best_result['y_test'],\n",
    "        best_result['y_pred'],\n",
    "        target_names=['Closed', 'Open']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    \"\"\"Save best pipeline\"\"\"\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "\n",
    "    pipeline_data = {\n",
    "        'pipeline': classifier.best_pipeline,\n",
    "        'pipeline_name': classifier.best_pipeline_name,\n",
    "        'accuracy': classifier.best_accuracy,\n",
    "        'feature_count': 25\n",
    "    }\n",
    "\n",
    "    with open('models/eye_classifier.pkl', 'wb') as f:\n",
    "        pickle.dump(pipeline_data, f)\n",
    "\n",
    "    print(f\"üíæ Pipeline saved: models/eye_classifier.pkl\")\n",
    "\n",
    "# Save the best model\n",
    "if len(X) > 0 and classifier.best_pipeline is not None:\n",
    "    save_model()\n",
    "    \n",
    "    print(\"\\n‚úÖ Training completed successfully!\")\n",
    "    print(\"üìÅ Files saved:\")\n",
    "    print(\"   - models/eye_classifier.pkl (trained model)\")\n",
    "    print(\"   - models/training_results.png (visualization)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
